{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook I use dask\n",
    "\n",
    "This is demonstrating how to use dask for our data processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_processing import load_data, get_files, parse_filename\n",
    "from feature_extraction import extract_fft_features, extract_time_domain_features\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask import do\n",
    "from os.path import split\n",
    "from dask import delayed, compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files =get_files()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_filename(filename, split_file=False):\n",
    "    \"\"\"Parses m filename to get the pertinent information\"\"\"\n",
    "    if split_file:\n",
    "        filename = split(filename)[1]\n",
    "\n",
    "    # strip out the .mat\n",
    "    filename = filename.replace('.mat', '')\n",
    "\n",
    "    # parse the remaing part\n",
    "    return [int(part) for part in filename.split('_')]\n",
    "\n",
    "def map_functions(data, functions):\n",
    "    \"\"\"maps a list of functions to data and returns as a list of results\n",
    "    Parameters: \n",
    "        data: data to be computed on\n",
    "        functions(list): a list of functions\n",
    "    Returns: \n",
    "        results(list): a list of the results\n",
    "    \"\"\"\n",
    "    return [fun(data) for fun in functions]\n",
    "\n",
    "\n",
    "def process_data(file_name, functions=None):\n",
    "    \"\"\"Processes one file at a time for extracting features\n",
    "    Parameters: \n",
    "        file_name(str): the file name\n",
    "        functions(list): a list of functions for extracting features\n",
    "    Returns: \n",
    "        res(pd.DataFrame): a one row data frame with the features in the columns    \n",
    "    \"\"\"\n",
    "    \n",
    "    if functions is None: \n",
    "        functions = [extract_time_domain_features,extract_fft_features]\n",
    "    \n",
    "    # get the time series and parse the filename for the info\n",
    "    time_series = load_data(file_name,True)[0]\n",
    "    patient,number,condition = parse_filename(file_name, True)\n",
    "    \n",
    "    # create an index and prefix df\n",
    "    index = pd.MultiIndex.from_tuples([(patient, number, condition)], \n",
    "                                      names=['Patient', 'TraceNumber', 'Condition'])\n",
    "\n",
    "    prefix_df = pd.DataFrame({'Patient':patient,\n",
    "                              'TraceNumber':number,\n",
    "                              'Condition':condition},\n",
    "                             index = [0]\n",
    "                              )\n",
    "    \n",
    "    # create a list two hold the data frames, call the functions and then concatenate the resulting dataframes\n",
    "    res = [prefix_df]\n",
    "    res.extend(map_functions(time_series,functions))\n",
    "    res = pd.concat(res, axis =1)\n",
    "    res.index = index\n",
    "    return res\n",
    "    \n",
    "def process_multiple_data(files):\n",
    "    \"\"\"uses dask to process many files in parallel\"\"\"\n",
    "    # set up the compute graph\n",
    "    graph = delayed([delayed(process_data)(file_) for file_ in files])\n",
    "    # compute the graph\n",
    "    results = compute(graph)\n",
    "    \n",
    "    return pd.concat([results[0][i] for i in range(len(files))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "features = process_multiple_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_functions(data, functions):\n",
    "    \"\"\"maps a list of functions to data (slowly)\"\"\"\n",
    "    return [fun(data) for fun in functions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import numpy as np\n",
    "functions = [np.sin, np.cos]\n",
    "map_functions(1,functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try the new code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, split\n",
    "from data_processing import Processor,get_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processor = Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_path =['/Users/crivera5/Desktop/test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_file() takes exactly 3 arguments (2 given)\n\nTraceback\n---------\n  File \"/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/async.py\", line 268, in execute_task\n    result = _execute_task(task, data)\n  File \"/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/async.py\", line 249, in _execute_task\n    return func(*args2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f72c593ac81e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/crivera5/Documents/NonIntuitProjects/Kaggle/KaggleEEG/data_processing/data_processing.py\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(self, list_of_directories)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# seizure_df = pd.DataFrame()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# failures = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mresults_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/multiprocessing.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         result = get_async(pool.apply_async, len(pool._pool), dsk3, keys,\n\u001b[1;32m     83\u001b[0m                            \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_process_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                            dumps=dumps, loads=loads, **kwargs)\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/async.pyc\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, raise_on_exception, rerun_exceptions_locally, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m                     \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cache'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mfinish_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: process_file() takes exactly 3 arguments (2 given)\n\nTraceback\n---------\n  File \"/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/async.py\", line 268, in execute_task\n    result = _execute_task(task, data)\n  File \"/Users/crivera5/.virtual_envs/Kaggle/lib/python2.7/site-packages/dask/async.py\", line 249, in _execute_task\n    return func(*args2)\n"
     ]
    }
   ],
   "source": [
    "res = processor.process_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
