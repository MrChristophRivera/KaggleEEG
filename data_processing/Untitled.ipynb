{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "from feature_extraction import *\n",
    "from transformations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = \"D:/Users/Anthony/Documents/Kaggle-Competitions/KaggleEEG/data_processing/\"\n",
    "train1_path = join(base, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Processor(object):\n",
    "\n",
    "    def __init__(self, list_of_functions, dtrend=None):\n",
    "        self.list_of_functions = list_of_functions\n",
    "        self.dtrend = dtrend\n",
    "\n",
    "    def process_folder(self, train_path, function_name):\n",
    "        \"\"\" Apply function to all files in\n",
    "        \"\"\"\n",
    "        seizure_df = pd.DataFrame()\n",
    "        failures = []\n",
    "        results = []\n",
    "        print(train_path)\n",
    "        for patient_path in train_path:\n",
    "            # This is how I speed up processing 4x by making full use of all cores in the CPUs.\n",
    "            values = [delayed(function_name)('\\\\'.join([patient_path, f])) for f in listdir(patient_path) if isfile('/'.join([patient_path, f]))]\n",
    "            result = compute(*values, get=dask.multiprocessing.get)\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "    def process_file(self, fname):\n",
    "        \"\"\" Apply list of functions to file.\n",
    "\n",
    "        Each function should return a dataframe with x columns and 1 row. The number of columns is equal to features\n",
    "        extracted.\n",
    "\n",
    "        :param fname:\n",
    "        :param list_of_functions:\n",
    "        :param dtrend (string):  Must be  'None', 'mean', 'median'\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        print(fname)\n",
    "        #base_path, target_path, f = fname.split('\\\\')\n",
    "        #path = '\\\\'.join([base_path, target_path])\n",
    "        #print('processing', path, f)\n",
    "        df, sampling_rate, sequence = load_data(join(fname))\n",
    "        df = self.normalize(df)\n",
    "        # Determine if this is an inter or preictal dataset and put in corresponding bucket.\n",
    "        split_string = fname.split('/').pop().replace('.', '_').split('_')\n",
    "        feature_df_list = []\n",
    "        for func in self.list_of_functions:\n",
    "            # Process function and append index columns\n",
    "            func_result_df = func(df)\n",
    "            feature_df_list.append(func_result_df)\n",
    "        feature_df = pd.concat(feature_df_list, 1)\n",
    "        feature_df = self.append_index(feature_df, split_string)\n",
    "        return feature_df\n",
    "\n",
    "    def append_index(self, df, split_string):\n",
    "        \"\"\" Append data set identifier and set index to identifier\"\"\"\n",
    "        df['patient'] = split_string[0]\n",
    "        df['dataset_id'] = split_string[1]\n",
    "        df['pre_ictal'] = split_string[2]\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def normalize(self, df):\n",
    "        \"\"\" Normalize data frame.\n",
    "        \"\"\"\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = Processor([extract_means, extract_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Users/Anthony/Documents/Kaggle-Competitions/KaggleEEG/data_processing/test']\n"
     ]
    }
   ],
   "source": [
    "res = test.process_folder([train1_path], test.process_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
