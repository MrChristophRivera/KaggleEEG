{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sb\n",
    "import re\n",
    "from os.path import join, dirname\n",
    "from scipy.io import loadmat\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_index_to_timedelta(index, sampling_rate=400):\n",
    "    \"\"\"converts the index to time delta\"\"\"\n",
    "    index = [i*1.0/sampling_rate for i in index]\n",
    "    return pd.to_timedelta(index,'s')\n",
    "    \n",
    "\n",
    "def load_data(path,convert_index=True):\n",
    "    \"\"\"converts the data to a pandas object\n",
    "    Parameters: \n",
    "        path(str): absolute path to the m file \n",
    "        convert_index(bool): if True, convert the index to a time delta\n",
    "    Returns: \n",
    "        (data,sampling_rate,sequence):(pd.DataFrame, int, int) \n",
    "    \"\"\"\n",
    "    # load the matlab file and extract the data\n",
    "    data = loadmat(path)['dataStruct']\n",
    "    \n",
    "    # get the sampling rate and cast to int\n",
    "    sampling_rate = int(data['iEEGsamplingRate'][0][0])\n",
    "    \n",
    "    #extract the iEEG traces and electrode channel data and place into a data frame\n",
    "    traces = data['data'][0][0]\n",
    "    channels = data['channelIndices'][0][0][0]\n",
    "    df = pd.DataFrame(traces, columns = channels)\n",
    "    \n",
    "    if convert_index: \n",
    "        df.index = convert_index_to_timedelta(df.index, sampling_rate)\n",
    "    \n",
    "    #get the sequence collection number if present (not present in test)\n",
    "    sequence = -1\n",
    "    if 'sequence' in data.dtype.names:\n",
    "        sequence =int(data['sequence'])\n",
    "\n",
    "    return df, sampling_rate, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.multiprocessing\n",
    "from dask import compute, delayed\n",
    "\n",
    "def process_folder(train_path, function_name):\n",
    "    seizure_df = pd.DataFrame()\n",
    "    failures = []\n",
    "    results = []\n",
    "    print(train_path)\n",
    "    for patient_path in train_path:\n",
    "        # This is how I speed up processing 4x by making full use of all cores in the CPUs.\n",
    "        values = [delayed(function_name)('\\\\'.join([patient_path, f])) for f in listdir(patient_path) if isfile('/'.join([patient_path, f]))]        \n",
    "        result = compute(*values, get=dask.multiprocessing.get)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def calculate_median_variance(input_path_file):\n",
    "    base_path, target_path, f = input_path_file.split('\\\\')\n",
    "    print(base_path, target_path)\n",
    "    path = '\\\\'.join([base_path, target_path])\n",
    "    print('processing', path, f)\n",
    "    this_file_df = pd.DataFrame()\n",
    "    this_file_dict = {}\n",
    "    try:\n",
    "        df, sampling_rate, sequence = load_data(join(path, f))\n",
    "        df.columns = [i for i in range(0,16)]\n",
    "        # Determine if this is an inter or preictal dataset and put in corresponding bucket.\n",
    "        split_string = f.replace('.', '_').split('_')\n",
    "        print(split_string)\n",
    "        for electrode in range(0,16):\n",
    "            this_file_dict[str(electrode)+'_mean'] = [df[electrode].mean()]\n",
    "            this_file_dict[str(electrode)+'_std'] = [df[electrode].std()]\n",
    "            this_file_dict[str(electrode)+'_med'] = [df[electrode].median()]\n",
    "            this_file_dict[str(electrode)+'_mad'] = [df[electrode].mad()]\n",
    "        this_file_df = pd.DataFrame(this_file_dict)\n",
    "        this_file_df['dataset_id'] = split_string[1]\n",
    "        this_file_df['pre_ictal'] = split_string[2]\n",
    "        this_file_df['patient'] = split_string[0]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return this_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_nulls(input_path_file):\n",
    "    base_path, target_path, f = input_path_file.split('\\\\')\n",
    "    print(base_path, target_path)\n",
    "    path = '\\\\'.join([base_path, target_path])\n",
    "    print('processing', path, f)\n",
    "    this_file_df = pd.DataFrame()\n",
    "    this_file_dict = {}\n",
    "    try:\n",
    "        df, sampling_rate, sequence = load_data(join(path, f))\n",
    "        df.columns = [i for i in range(0,16)]\n",
    "        # Determine if this is an inter or preictal dataset and put in corresponding bucket.\n",
    "        split_string = f.replace('.', '_').split('_')\n",
    "        print(split_string)\n",
    "        no_contact_df = df.query(1 == 0 and 2 == 0 and 3 == 0 and 4 == 0 and 5 == 0 and\n",
    "                                 6 == 0 and 7 == 0 and 8 == 0 and 9 == 0 and 10 == 0 and\n",
    "                                 11 == 0 and 12 == 0 and 13 == 0 and 14 == 0 and 15 == 0 and\n",
    "                                 16 == 0)\n",
    "        if not no_contact_df.empty:\n",
    "            return input_path_file\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up the path\n",
    "base = \"D:/Users/Anthony/Documents/Kaggle-Competitions/Kaggle-EKK-Data\"\n",
    "train1_path = join(base, 'train_1')\n",
    "train2_path = join(base, 'train_2')\n",
    "train3_path = join(base, 'train_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Users/Anthony/Documents/Kaggle-Competitions/Kaggle-EKK-Data\\\\train_2', 'D:/Users/Anthony/Documents/Kaggle-Competitions/Kaggle-EKK-Data\\\\train_3']\n"
     ]
    }
   ],
   "source": [
    "no_contact_res = process_folder([train2_path, train3_path], check_for_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(), ()]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
